{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6350334-759e-43ff-a023-4a48c9aa52b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "  Downloading librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.20.1-cp312-cp312-win_amd64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\ual-laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ual-laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.2)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\ual-laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\ual-laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa) (1.5.1)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\ual-laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\ual-laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Collecting numba>=0.51.0 (from librosa)\n",
      "  Downloading numba-0.60.0-cp312-cp312-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting soundfile>=0.12.1 (from librosa)\n",
      "  Downloading soundfile-0.12.1-py2.py3-none-win_amd64.whl.metadata (14 kB)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Downloading soxr-0.5.0.post1-cp312-abi3-win_amd64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\ual-laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa) (4.12.2)\n",
      "Collecting lazy-loader>=0.1 (from librosa)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa)\n",
      "  Downloading msgpack-1.1.0-cp312-cp312-win_amd64.whl.metadata (8.6 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ual-laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ual-laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (74.0.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ual-laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ual-laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ual-laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ual-laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ual-laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ual-laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ual-laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ual-laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba>=0.51.0->librosa)\n",
      "  Downloading llvmlite-0.43.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\ual-laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pooch>=1.1->librosa) (4.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\ual-laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ual-laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ual-laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\ual-laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ual-laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: pycparser in c:\\users\\ual-laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ual-laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ual-laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ual-laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ual-laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.2.2)\n",
      "Downloading librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
      "Downloading torch-2.5.1-cp312-cp312-win_amd64.whl (203.0 MB)\n",
      "   ---------------------------------------- 0.0/203.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.8/203.0 MB 5.6 MB/s eta 0:00:37\n",
      "   ---------------------------------------- 1.8/203.0 MB 4.8 MB/s eta 0:00:42\n",
      "    --------------------------------------- 2.9/203.0 MB 4.8 MB/s eta 0:00:42\n",
      "    --------------------------------------- 3.9/203.0 MB 4.9 MB/s eta 0:00:41\n",
      "    --------------------------------------- 5.0/203.0 MB 4.9 MB/s eta 0:00:41\n",
      "   - -------------------------------------- 6.0/203.0 MB 4.9 MB/s eta 0:00:41\n",
      "   - -------------------------------------- 7.1/203.0 MB 4.8 MB/s eta 0:00:41\n",
      "   - -------------------------------------- 7.9/203.0 MB 4.7 MB/s eta 0:00:42\n",
      "   - -------------------------------------- 8.9/203.0 MB 4.7 MB/s eta 0:00:42\n",
      "   - -------------------------------------- 10.0/203.0 MB 4.7 MB/s eta 0:00:41\n",
      "   -- ------------------------------------- 11.0/203.0 MB 4.7 MB/s eta 0:00:41\n",
      "   -- ------------------------------------- 12.1/203.0 MB 4.8 MB/s eta 0:00:40\n",
      "   -- ------------------------------------- 13.1/203.0 MB 4.8 MB/s eta 0:00:40\n",
      "   -- ------------------------------------- 14.2/203.0 MB 4.8 MB/s eta 0:00:40\n",
      "   -- ------------------------------------- 15.2/203.0 MB 4.8 MB/s eta 0:00:40\n",
      "   --- ------------------------------------ 16.3/203.0 MB 4.8 MB/s eta 0:00:40\n",
      "   --- ------------------------------------ 17.0/203.0 MB 4.8 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 18.1/203.0 MB 4.8 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 19.1/203.0 MB 4.8 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 20.2/203.0 MB 4.8 MB/s eta 0:00:39\n",
      "   ---- ----------------------------------- 21.2/203.0 MB 4.8 MB/s eta 0:00:38\n",
      "   ---- ----------------------------------- 22.3/203.0 MB 4.8 MB/s eta 0:00:38\n",
      "   ---- ----------------------------------- 23.3/203.0 MB 4.8 MB/s eta 0:00:38\n",
      "   ---- ----------------------------------- 24.4/203.0 MB 4.8 MB/s eta 0:00:38\n",
      "   ----- ---------------------------------- 25.4/203.0 MB 4.8 MB/s eta 0:00:38\n",
      "   ----- ---------------------------------- 26.2/203.0 MB 4.8 MB/s eta 0:00:37\n",
      "   ----- ---------------------------------- 27.0/203.0 MB 4.8 MB/s eta 0:00:37\n",
      "   ----- ---------------------------------- 28.3/203.0 MB 4.8 MB/s eta 0:00:37\n",
      "   ----- ---------------------------------- 29.4/203.0 MB 4.8 MB/s eta 0:00:37\n",
      "   ----- ---------------------------------- 30.1/203.0 MB 4.8 MB/s eta 0:00:37\n",
      "   ------ --------------------------------- 31.2/203.0 MB 4.8 MB/s eta 0:00:36\n",
      "   ------ --------------------------------- 32.2/203.0 MB 4.8 MB/s eta 0:00:36\n",
      "   ------ --------------------------------- 33.3/203.0 MB 4.8 MB/s eta 0:00:36\n",
      "   ------ --------------------------------- 34.3/203.0 MB 4.8 MB/s eta 0:00:36\n",
      "   ------ --------------------------------- 35.4/203.0 MB 4.8 MB/s eta 0:00:36\n",
      "   ------- -------------------------------- 36.4/203.0 MB 4.8 MB/s eta 0:00:35\n",
      "   ------- -------------------------------- 37.5/203.0 MB 4.8 MB/s eta 0:00:35\n",
      "   ------- -------------------------------- 38.3/203.0 MB 4.8 MB/s eta 0:00:35\n",
      "   ------- -------------------------------- 39.3/203.0 MB 4.8 MB/s eta 0:00:35\n",
      "   ------- -------------------------------- 40.4/203.0 MB 4.8 MB/s eta 0:00:35\n",
      "   -------- ------------------------------- 41.4/203.0 MB 4.8 MB/s eta 0:00:34\n",
      "   -------- ------------------------------- 42.2/203.0 MB 4.8 MB/s eta 0:00:34\n",
      "   -------- ------------------------------- 43.5/203.0 MB 4.8 MB/s eta 0:00:34\n",
      "   -------- ------------------------------- 44.3/203.0 MB 4.8 MB/s eta 0:00:34\n",
      "   -------- ------------------------------- 45.4/203.0 MB 4.8 MB/s eta 0:00:33\n",
      "   --------- ------------------------------ 46.1/203.0 MB 4.8 MB/s eta 0:00:33\n",
      "   --------- ------------------------------ 46.9/203.0 MB 4.7 MB/s eta 0:00:33\n",
      "   --------- ------------------------------ 48.0/203.0 MB 4.7 MB/s eta 0:00:33\n",
      "   --------- ------------------------------ 49.0/203.0 MB 4.8 MB/s eta 0:00:33\n",
      "   --------- ------------------------------ 50.1/203.0 MB 4.8 MB/s eta 0:00:33\n",
      "   ---------- ----------------------------- 50.9/203.0 MB 4.7 MB/s eta 0:00:33\n",
      "   ---------- ----------------------------- 51.9/203.0 MB 4.7 MB/s eta 0:00:32\n",
      "   ---------- ----------------------------- 53.0/203.0 MB 4.7 MB/s eta 0:00:32\n",
      "   ---------- ----------------------------- 53.7/203.0 MB 4.7 MB/s eta 0:00:32\n",
      "   ---------- ----------------------------- 54.5/203.0 MB 4.7 MB/s eta 0:00:32\n",
      "   ---------- ----------------------------- 55.6/203.0 MB 4.7 MB/s eta 0:00:32\n",
      "   ----------- ---------------------------- 56.6/203.0 MB 4.7 MB/s eta 0:00:31\n",
      "   ----------- ---------------------------- 57.7/203.0 MB 4.7 MB/s eta 0:00:31\n",
      "   ----------- ---------------------------- 58.5/203.0 MB 4.7 MB/s eta 0:00:31\n",
      "   ----------- ---------------------------- 59.5/203.0 MB 4.7 MB/s eta 0:00:31\n",
      "   ----------- ---------------------------- 60.6/203.0 MB 4.7 MB/s eta 0:00:31\n",
      "   ------------ --------------------------- 61.6/203.0 MB 4.7 MB/s eta 0:00:30\n",
      "   ------------ --------------------------- 62.7/203.0 MB 4.7 MB/s eta 0:00:30\n",
      "   ------------ --------------------------- 63.7/203.0 MB 4.7 MB/s eta 0:00:30\n",
      "   ------------ --------------------------- 64.5/203.0 MB 4.7 MB/s eta 0:00:30\n",
      "   ------------ --------------------------- 65.5/203.0 MB 4.7 MB/s eta 0:00:30\n",
      "   ------------- -------------------------- 66.6/203.0 MB 4.7 MB/s eta 0:00:29\n",
      "   ------------- -------------------------- 67.6/203.0 MB 4.7 MB/s eta 0:00:29\n",
      "   ------------- -------------------------- 68.7/203.0 MB 4.7 MB/s eta 0:00:29\n",
      "   ------------- -------------------------- 69.7/203.0 MB 4.7 MB/s eta 0:00:29\n",
      "   ------------- -------------------------- 70.8/203.0 MB 4.7 MB/s eta 0:00:28\n",
      "   -------------- ------------------------- 71.6/203.0 MB 4.7 MB/s eta 0:00:28\n",
      "   -------------- ------------------------- 72.6/203.0 MB 4.7 MB/s eta 0:00:28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~otebook (C:\\Users\\ual-laptop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~otebook (C:\\Users\\ual-laptop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~otebook (C:\\Users\\ual-laptop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -------------- ------------------------- 73.7/203.0 MB 4.7 MB/s eta 0:00:28\n",
      "   -------------- ------------------------- 74.4/203.0 MB 4.7 MB/s eta 0:00:28\n",
      "   -------------- ------------------------- 75.5/203.0 MB 4.7 MB/s eta 0:00:27\n",
      "   --------------- ------------------------ 76.5/203.0 MB 4.7 MB/s eta 0:00:27\n",
      "   --------------- ------------------------ 77.6/203.0 MB 4.7 MB/s eta 0:00:27\n",
      "   --------------- ------------------------ 78.6/203.0 MB 4.7 MB/s eta 0:00:27\n",
      "   --------------- ------------------------ 79.7/203.0 MB 4.7 MB/s eta 0:00:27\n",
      "   --------------- ------------------------ 80.7/203.0 MB 4.7 MB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 81.5/203.0 MB 4.7 MB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 82.6/203.0 MB 4.7 MB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 83.6/203.0 MB 4.7 MB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 84.7/203.0 MB 4.7 MB/s eta 0:00:25\n",
      "   ---------------- ----------------------- 85.7/203.0 MB 4.7 MB/s eta 0:00:25\n",
      "   ----------------- ---------------------- 86.8/203.0 MB 4.7 MB/s eta 0:00:25\n",
      "   ----------------- ---------------------- 87.8/203.0 MB 4.7 MB/s eta 0:00:25\n",
      "   ----------------- ---------------------- 88.6/203.0 MB 4.7 MB/s eta 0:00:25\n",
      "   ----------------- ---------------------- 89.7/203.0 MB 4.7 MB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 90.7/203.0 MB 4.7 MB/s eta 0:00:24\n",
      "   ------------------ --------------------- 91.5/203.0 MB 4.7 MB/s eta 0:00:24\n",
      "   ------------------ --------------------- 92.5/203.0 MB 4.7 MB/s eta 0:00:24\n",
      "   ------------------ --------------------- 93.6/203.0 MB 4.7 MB/s eta 0:00:24\n",
      "   ------------------ --------------------- 94.6/203.0 MB 4.7 MB/s eta 0:00:23\n",
      "   ------------------ --------------------- 95.2/203.0 MB 4.7 MB/s eta 0:00:23\n",
      "   ------------------ --------------------- 96.2/203.0 MB 4.7 MB/s eta 0:00:23\n",
      "   ------------------- -------------------- 97.3/203.0 MB 4.7 MB/s eta 0:00:23\n",
      "   ------------------- -------------------- 98.3/203.0 MB 4.7 MB/s eta 0:00:23\n",
      "   ------------------- -------------------- 99.1/203.0 MB 4.7 MB/s eta 0:00:23\n",
      "   ------------------- -------------------- 100.1/203.0 MB 4.7 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 101.2/203.0 MB 4.7 MB/s eta 0:00:22\n",
      "   -------------------- ------------------- 102.2/203.0 MB 4.7 MB/s eta 0:00:22\n",
      "   -------------------- ------------------- 103.0/203.0 MB 4.7 MB/s eta 0:00:22\n",
      "   -------------------- ------------------- 104.3/203.0 MB 4.7 MB/s eta 0:00:21\n",
      "   -------------------- ------------------- 105.4/203.0 MB 4.7 MB/s eta 0:00:21\n",
      "   -------------------- ------------------- 106.2/203.0 MB 4.7 MB/s eta 0:00:21\n",
      "   --------------------- ------------------ 107.2/203.0 MB 4.7 MB/s eta 0:00:21\n",
      "   --------------------- ------------------ 108.3/203.0 MB 4.7 MB/s eta 0:00:21\n",
      "   --------------------- ------------------ 109.3/203.0 MB 4.7 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 110.4/203.0 MB 4.7 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 111.4/203.0 MB 4.7 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 112.5/203.0 MB 4.7 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 113.5/203.0 MB 4.7 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 114.6/203.0 MB 4.7 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 115.3/203.0 MB 4.7 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 116.4/203.0 MB 4.7 MB/s eta 0:00:19\n",
      "   ----------------------- ---------------- 117.4/203.0 MB 4.7 MB/s eta 0:00:19\n",
      "   ----------------------- ---------------- 118.5/203.0 MB 4.7 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 119.5/203.0 MB 4.7 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 120.6/203.0 MB 4.7 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 121.4/203.0 MB 4.7 MB/s eta 0:00:18\n",
      "   ------------------------ --------------- 122.4/203.0 MB 4.7 MB/s eta 0:00:18\n",
      "   ------------------------ --------------- 123.5/203.0 MB 4.7 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 124.5/203.0 MB 4.7 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 125.3/203.0 MB 4.7 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 126.4/203.0 MB 4.7 MB/s eta 0:00:17\n",
      "   ------------------------- -------------- 127.4/203.0 MB 4.7 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 128.5/203.0 MB 4.7 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 129.2/203.0 MB 4.7 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 130.3/203.0 MB 4.7 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 131.3/203.0 MB 4.7 MB/s eta 0:00:16\n",
      "   -------------------------- ------------- 132.1/203.0 MB 4.7 MB/s eta 0:00:16\n",
      "   -------------------------- ------------- 133.2/203.0 MB 4.7 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 134.2/203.0 MB 4.7 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 135.3/203.0 MB 4.7 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 136.1/203.0 MB 4.7 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 137.1/203.0 MB 4.7 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 138.1/203.0 MB 4.7 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 139.2/203.0 MB 4.7 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 140.0/203.0 MB 4.7 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 141.0/203.0 MB 4.7 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 141.8/203.0 MB 4.7 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 143.1/203.0 MB 4.7 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 143.9/203.0 MB 4.7 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 145.0/203.0 MB 4.7 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 146.0/203.0 MB 4.7 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 146.8/203.0 MB 4.7 MB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 147.8/203.0 MB 4.7 MB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 148.9/203.0 MB 4.7 MB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 149.7/203.0 MB 4.7 MB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 150.7/203.0 MB 4.7 MB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 151.5/203.0 MB 4.7 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 152.6/203.0 MB 4.7 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 153.6/203.0 MB 4.7 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 154.7/203.0 MB 4.7 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 155.5/203.0 MB 4.7 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 156.5/203.0 MB 4.7 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 157.5/203.0 MB 4.7 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 158.3/203.0 MB 4.7 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 159.4/203.0 MB 4.7 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 160.4/203.0 MB 4.7 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 161.2/203.0 MB 4.7 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 162.0/203.0 MB 4.7 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 163.3/203.0 MB 4.7 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 164.1/203.0 MB 4.7 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 165.2/203.0 MB 4.7 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 166.2/203.0 MB 4.7 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 167.2/203.0 MB 4.7 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 168.0/203.0 MB 4.7 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 168.6/203.0 MB 4.7 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 169.3/203.0 MB 4.7 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 170.7/203.0 MB 4.7 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 171.7/203.0 MB 4.7 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 172.5/203.0 MB 4.7 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 173.5/203.0 MB 4.7 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 174.1/203.0 MB 4.7 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 174.6/203.0 MB 4.7 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 174.9/203.0 MB 4.7 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 175.4/203.0 MB 4.6 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 175.9/203.0 MB 4.6 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 176.4/203.0 MB 4.6 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 176.9/203.0 MB 4.6 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 177.5/203.0 MB 4.6 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 178.0/203.0 MB 4.6 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 178.8/203.0 MB 4.6 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 179.6/203.0 MB 4.5 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 180.1/203.0 MB 4.5 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 180.6/203.0 MB 4.5 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 181.1/203.0 MB 4.5 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 182.2/203.0 MB 4.5 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 182.7/203.0 MB 4.5 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 183.8/203.0 MB 4.5 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 184.5/203.0 MB 4.5 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 185.6/203.0 MB 4.5 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 186.6/203.0 MB 4.5 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 187.2/203.0 MB 4.5 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 188.2/203.0 MB 4.5 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 189.3/203.0 MB 4.5 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 190.3/203.0 MB 4.5 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 191.4/203.0 MB 4.5 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 192.2/203.0 MB 4.5 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 192.7/203.0 MB 4.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 193.7/203.0 MB 4.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 194.8/203.0 MB 4.5 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 195.8/203.0 MB 4.5 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 196.9/203.0 MB 4.5 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 197.9/203.0 MB 4.5 MB/s eta 0:00:02\n",
      "   ---------------------------------------  199.0/203.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.8/203.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  200.8/203.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  201.6/203.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.6/203.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.9/203.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.9/203.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.9/203.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.9/203.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.9/203.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.9/203.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.9/203.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.9/203.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.9/203.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.9/203.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.9/203.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.9/203.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.9/203.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.9/203.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.9/203.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 203.0/203.0 MB 4.0 MB/s eta 0:00:00\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.8/6.2 MB 4.8 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 1.8/6.2 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.6/6.2 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.4/6.2 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.5/6.2 MB 4.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.5/6.2 MB 4.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.0/6.2 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 4.1 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.20.1-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.8/1.6 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 3.6 MB/s eta 0:00:00\n",
      "Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading msgpack-1.1.0-cp312-cp312-win_amd64.whl (75 kB)\n",
      "Downloading numba-0.60.0-cp312-cp312-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.8/2.7 MB 3.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.6/2.7 MB 4.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.6/2.7 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 4.0 MB/s eta 0:00:00\n",
      "Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Downloading soundfile-0.12.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ------------------------------- -------- 0.8/1.0 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 4.3 MB/s eta 0:00:00\n",
      "Downloading soxr-0.5.0.post1-cp312-abi3-win_amd64.whl (164 kB)\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 0.8/1.7 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.6/1.7 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 3.7 MB/s eta 0:00:00\n",
      "Downloading llvmlite-0.43.0-cp312-cp312-win_amd64.whl (28.1 MB)\n",
      "   ---------------------------------------- 0.0/28.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/28.1 MB 5.6 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 2.1/28.1 MB 5.1 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 3.1/28.1 MB 5.0 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 3.7/28.1 MB 4.8 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 5.0/28.1 MB 4.8 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 6.0/28.1 MB 4.8 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 6.8/28.1 MB 4.8 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 7.9/28.1 MB 4.8 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 8.9/28.1 MB 4.7 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 9.7/28.1 MB 4.8 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 10.7/28.1 MB 4.8 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 11.8/28.1 MB 4.7 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 12.3/28.1 MB 4.6 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 13.1/28.1 MB 4.6 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 14.2/28.1 MB 4.6 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 14.9/28.1 MB 4.5 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 16.0/28.1 MB 4.6 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 16.8/28.1 MB 4.5 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 17.6/28.1 MB 4.5 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 18.6/28.1 MB 4.5 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 19.7/28.1 MB 4.5 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 20.4/28.1 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 21.5/28.1 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 22.3/28.1 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 23.3/28.1 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 23.9/28.1 MB 4.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 25.2/28.1 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 26.0/28.1 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 26.5/28.1 MB 4.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 27.3/28.1 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.0/28.1 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.0/28.1 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.0/28.1 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.0/28.1 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 28.1/28.1 MB 4.0 MB/s eta 0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 536.2/536.2 kB 2.5 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, soxr, networkx, msgpack, llvmlite, lazy-loader, fsspec, filelock, audioread, torch, soundfile, pooch, numba, torchvision, librosa\n",
      "Successfully installed audioread-3.0.1 filelock-3.16.1 fsspec-2024.10.0 lazy-loader-0.4 librosa-0.10.2.post1 llvmlite-0.43.0 mpmath-1.3.0 msgpack-1.1.0 networkx-3.4.2 numba-0.60.0 pooch-1.8.2 soundfile-0.12.1 soxr-0.5.0.post1 sympy-1.13.1 torch-2.5.1 torchvision-0.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa torch torchvision numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cbe436f-20e2-40c7-b6b2-0b02eb8dbd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "SAMPLE_RATE = 22050    # Sample rate for audio\n",
    "N_MELS = 64            # Number of Mel bands in spectrogram\n",
    "AUDIO_LENGTH = 2.0     # Length of each audio sample in seconds\n",
    "BATCH_SIZE = 32        # Batch size for training\n",
    "DATA_DIR = \"data\"      # Parent directory containing 'clear' and 'wheeze' folders\n",
    "\n",
    "# Data augmentation transformations\n",
    "def audio_augmentations(audio):\n",
    "    noise = np.random.randn(len(audio))\n",
    "    audio = audio + 0.005 * noise  # Adding Gaussian noise as an augmentation\n",
    "    return audio\n",
    "\n",
    "# Convert audio to Mel spectrogram\n",
    "def audio_to_melspectrogram(audio, sr=SAMPLE_RATE, n_mels=N_MELS):\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=n_mels)\n",
    "    mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    return mel_spectrogram\n",
    "\n",
    "class WheezeDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.file_paths = []\n",
    "        self.labels = []\n",
    "        for label, folder_name in enumerate(['clear', 'wheeze']):\n",
    "            folder_path = os.path.join(data_dir, folder_name)\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                if file_name.endswith('.wav'):  # Ensure only audio files are included\n",
    "                    self.file_paths.append(os.path.join(folder_path, file_name))\n",
    "                    self.labels.append(label)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_paths[idx]\n",
    "        try:\n",
    "            audio, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "            # Ensure consistent audio length\n",
    "            if len(audio) < SAMPLE_RATE * AUDIO_LENGTH:\n",
    "                padding = SAMPLE_RATE * AUDIO_LENGTH - len(audio)\n",
    "                audio = np.pad(audio, (0, padding), mode='constant')\n",
    "            else:\n",
    "                audio = audio[:SAMPLE_RATE * AUDIO_LENGTH]\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\")\n",
    "            return None  # Optionally handle invalid files\n",
    "\n",
    "        mel_spec = audio_to_melspectrogram(audio)\n",
    "        mel_spec = torch.tensor(mel_spec, dtype=torch.float32)\n",
    "\n",
    "        # Augmented version\n",
    "        aug_audio = audio_augmentations(audio)\n",
    "        aug_mel_spec = audio_to_melspectrogram(aug_audio)\n",
    "        aug_mel_spec = torch.tensor(aug_mel_spec, dtype=torch.float32)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return mel_spec.unsqueeze(0), aug_mel_spec.unsqueeze(0), label\n",
    "\n",
    "\n",
    "# Load dataset and create dataloader\n",
    "dataset = WheezeDataset(DATA_DIR)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84bdab2a-5cb0-4074-bd19-c46511bc688f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading data\\wheeze\\53155afb-a9af-448b-83b2-14052a2b2bf9.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\clear\\235cc3a4-a29a-4c9e-8d1a-a0c7a5b34027.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\wheeze\\27827f4d-744f-4550-89bb-857e320ec7a2.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\wheeze\\b8615581-b239-441a-bd79-9814c4d74e25.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\clear\\e4833296-15c4-4cb4-9d70-332b4aad2b89.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\clear\\ba6f07cc-f7b9-400a-a2cc-59e291434fbd.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\wheeze\\ef6a2fde-0cec-472d-a5f7-151cb1dd8cd1.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\wheeze\\4457e738-8a76-4559-bd8e-904edcf0e5f2.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\clear\\7ac43305-b109-4147-800a-f96584e58aec.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\clear\\4ae1fc84-8808-46b3-b47c-1897eec1dab9.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\wheeze\\7d65ca82-828f-4513-a877-8bea85b072fb.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\clear\\aa4391d3-c6fc-4a7b-a59e-b174b029d1ed.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\clear\\4e299cf9-da32-4b92-a674-da2e49662439.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\wheeze\\fa887c64-20fd-4e16-8f82-8c46f9300e34.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\clear\\2efd8ac3-e225-429d-9adc-2368c98c5968.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\clear\\c26d607e-c786-43a8-8e79-d6639758e69e.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\wheeze\\cd724cb3-c035-42c5-84f4-dcd4fa9a2702.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\wheeze\\e04d0599-c51b-46fd-95fb-7fd8def8ffcc.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\clear\\1a6a6ddc-4318-4d24-a34b-3c42e335e9e6.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\clear\\d5659b05-b4a9-4d94-9360-4a544d15fa5f.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\clear\\900cabc0-98be-4b72-97b1-945b862eb01f.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\clear\\eef92e88-9da3-48ca-890a-adcf4d6207ae.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\clear\\6bc0368c-7544-4567-85c3-df0d29a20112.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\wheeze\\a5892cce-3b95-4334-8044-bb085b43aff8.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\clear\\1f31f5f6-b053-432a-a5e9-e22c8e10a182.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\wheeze\\02f585b8-e591-485c-b47d-90f23e04b7fc.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\wheeze\\52732e5c-78c2-4713-a685-4dc69e038c30.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\clear\\02fcf3c1-a99f-43d7-b9ce-8f43a0b413a1.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\clear\\72a062f3-eaaf-4403-9708-9da813386ae8.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\clear\\674a9b41-f402-48cc-9b67-6672764df3d8.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\clear\\f93cfe99-8f10-4285-94b5-90e0f786356d.wav: slice indices must be integers or None or have an __index__ method\n",
      "Error loading data\\clear\\c124de82-7142-4bfd-bb7a-1578e6ac0d9d.wav: slice indices must be integers or None or have an __index__ method\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 47\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m     46\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x1, x2, _ \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m     48\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     49\u001b[0m         z1 \u001b[38;5;241m=\u001b[39m model(x1)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:398\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:240\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m             \u001b[38;5;66;03m# The sequence type may not support `copy()` / `__setitem__(index, item)`\u001b[39;00m\n\u001b[0;32m    234\u001b[0m             \u001b[38;5;66;03m# or `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[0;32m    235\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    236\u001b[0m                 collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n\u001b[0;32m    237\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[0;32m    238\u001b[0m             ]\n\u001b[1;32m--> 240\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem_type))\n",
      "\u001b[1;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimCLRModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimCLRModel, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        # Dynamically determine the flattened output size of the encoder\n",
    "        dummy_input = torch.randn(1, 1, N_MELS, int(SAMPLE_RATE * AUDIO_LENGTH / 512))\n",
    "        with torch.no_grad():\n",
    "            dummy_output = self.encoder(dummy_input)\n",
    "            flattened_size = dummy_output.shape[1]\n",
    "\n",
    "        # Use the dynamically calculated flattened size for the first linear layer\n",
    "        self.fc = nn.Linear(flattened_size, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "def contrastive_loss(features, temperature=0.5):\n",
    "    labels = torch.cat([torch.arange(features.shape[0]//2) for i in range(2)], dim=0)\n",
    "    labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
    "    features = nn.functional.normalize(features, dim=1)\n",
    "    similarity_matrix = torch.matmul(features, features.T) / temperature\n",
    "    loss = -torch.log(similarity_matrix.softmax(dim=1) + 1e-6)\n",
    "    loss = loss.mean()\n",
    "    return loss\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model = SimCLRModel()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training Loop for Self-Supervised Learning\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for x1, x2, _ in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        z1 = model(x1)\n",
    "        z2 = model(x2)\n",
    "        loss = contrastive_loss(torch.cat([z1, z2], dim=0))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/10], Loss: {total_loss/len(dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bb1afe-c0ec-47f6-a739-044402d1982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FineTuneModel(nn.Module):\n",
    "    def __init__(self, encoder):\n",
    "        super(FineTuneModel, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        \n",
    "        # Freeze encoder weights if needed\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Determine the flattened size of encoder output dynamically\n",
    "        dummy_input = torch.randn(1, 1, N_MELS, int(SAMPLE_RATE * AUDIO_LENGTH / 512))\n",
    "        with torch.no_grad():\n",
    "            dummy_output = self.encoder(dummy_input)\n",
    "            flattened_size = dummy_output.shape[1]\n",
    "        \n",
    "        # Define classifier with dynamically determined input size\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(flattened_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2)  # Assuming binary classification (clear vs. wheeze)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "\n",
    "# Initialize fine-tuning model and optimizer\n",
    "fine_tune_model = FineTuneModel(model.encoder)\n",
    "fine_tune_optimizer = optim.Adam(fine_tune_model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Fine-tuning loop\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for x, _, y in dataloader:\n",
    "        fine_tune_optimizer.zero_grad()\n",
    "        output = fine_tune_model(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        fine_tune_optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Fine-tuning Epoch [{epoch+1}/10], Loss: {total_loss/len(dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce9c0f0-cf48-4ee0-b3c9-6a72d0d5a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, auc, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the evaluation dataset (use the same WheezeDataset or a separate test dataset)\n",
    "class WheezeDatasetTest(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.file_paths = []\n",
    "        self.labels = []\n",
    "        for label, folder_name in enumerate(['clear', 'wheeze']):\n",
    "            folder_path = os.path.join(data_dir, folder_name)\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                self.file_paths.append(os.path.join(folder_path, file_name))\n",
    "                self.labels.append(label)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_paths[idx]\n",
    "        audio, sr = librosa.load(file_path, sr=SAMPLE_RATE, duration=AUDIO_LENGTH)\n",
    "        mel_spec = audio_to_melspectrogram(audio)\n",
    "        mel_spec = torch.tensor(mel_spec, dtype=torch.float32)\n",
    "        label = self.labels[idx]\n",
    "        return mel_spec.unsqueeze(0), label\n",
    "\n",
    "# Assuming you have a separate test directory or dataset for evaluation\n",
    "test_dataset = WheezeDatasetTest(DATA_DIR)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Define a function to calculate metrics\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    # Lists to store true labels and predictions\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    probabilities = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            # Get model outputs\n",
    "            output = model(x)\n",
    "            \n",
    "            # Predicted class labels\n",
    "            _, preds = torch.max(output, 1)\n",
    "            \n",
    "            # Predicted probabilities for the positive class (\"wheeze\")\n",
    "            probs = torch.softmax(output, dim=1)[:, 1]  # Assuming class 1 is \"wheeze\"\n",
    "            \n",
    "            # Store predictions and true labels\n",
    "            true_labels.extend(y.cpu().numpy())\n",
    "            predicted_labels.extend(preds.cpu().numpy())\n",
    "            probabilities.extend(probs.cpu().numpy())\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    true_labels = np.array(true_labels)\n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "    probabilities = np.array(probabilities)\n",
    "\n",
    "    # Compute evaluation metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels, pos_label=1)\n",
    "    recall = recall_score(true_labels, predicted_labels, pos_label=1)\n",
    "    f1 = f1_score(true_labels, predicted_labels, pos_label=1)\n",
    "    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    # ROC-AUC Score\n",
    "    roc_auc = roc_auc_score(true_labels, probabilities)\n",
    "\n",
    "    # Precision-Recall Curve and PR-AUC\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(true_labels, probabilities)\n",
    "    pr_auc = auc(recall_vals, precision_vals)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "    print(f\"PR-AUC: {pr_auc:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "\n",
    "    # Plot Precision-Recall Curve \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall_vals, precision_vals, label=f'PR-AUC = {pr_auc:.4f}')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "# Now, evaluate the fine-tuned model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "fine_tune_model.to(device)\n",
    "\n",
    "evaluate(fine_tune_model, test_dataloader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e4f3fa-0a39-45ea-858d-c52547c93040",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
